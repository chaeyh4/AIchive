{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iJtA70gbSQHc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "#from models.MLP import MLP_classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from MLP import MLP_classifier\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAyTHk_7zLFC",
        "outputId": "4218bdf2-3964-4290-c687-2c63a211158c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ZsxenUySQHf"
      },
      "outputs": [],
      "source": [
        "train_X = np.load('/content/drive/MyDrive/skku-ml2023-hw4/train_x.npy')\n",
        "train_y = np.load('/content/drive/MyDrive/skku-ml2023-hw4/train_y.npy')\n",
        "valid_X = np.load('/content/drive/MyDrive/skku-ml2023-hw4/valid_x.npy')\n",
        "valid_y = np.load('/content/drive/MyDrive/skku-ml2023-hw4/valid_y.npy')\n",
        "\n",
        "test_X = np.load('/content/drive/MyDrive/skku-ml2023-hw4/test_x.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP_7c2_RSQHg",
        "outputId": "8a0b590a-3527-4344-c086-33eeb123d6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of class (balanced train): Counter({0: 1200, 6: 1200, 7: 1200, 8: 1200, 9: 1200})\n",
            "# of class (balanced train): Counter({1: 1200, 2: 1200, 3: 1200, 4: 1200, 5: 1200})\n",
            "Epoch [1/80], Loss: 1.6097\n",
            "Accuracy: 75.60%\n",
            "Epoch [2/80], Loss: 1.6342\n",
            "Accuracy: 77.20%\n",
            "Epoch [3/80], Loss: 1.6247\n",
            "Accuracy: 76.60%\n",
            "Epoch [4/80], Loss: 1.6353\n",
            "Accuracy: 80.20%\n",
            "Epoch [5/80], Loss: 1.6299\n",
            "Accuracy: 81.40%\n",
            "Epoch [6/80], Loss: 1.6234\n",
            "Accuracy: 81.80%\n",
            "Epoch [7/80], Loss: 1.6217\n",
            "Accuracy: 80.40%\n",
            "Epoch [8/80], Loss: 1.6084\n",
            "Accuracy: 82.50%\n",
            "Epoch [9/80], Loss: 1.6926\n",
            "Accuracy: 81.30%\n",
            "Epoch [10/80], Loss: 1.5752\n",
            "Accuracy: 80.80%\n",
            "Epoch [11/80], Loss: 1.5733\n",
            "Accuracy: 82.00%\n",
            "Epoch [12/80], Loss: 1.6458\n",
            "Accuracy: 78.70%\n",
            "Epoch [13/80], Loss: 1.5648\n",
            "Accuracy: 82.80%\n",
            "Epoch [14/80], Loss: 1.5447\n",
            "Accuracy: 81.50%\n",
            "Epoch [15/80], Loss: 1.5536\n",
            "Accuracy: 81.40%\n",
            "Epoch [16/80], Loss: 1.5599\n",
            "Accuracy: 83.10%\n",
            "Epoch [17/80], Loss: 1.5111\n",
            "Accuracy: 80.90%\n",
            "Epoch [18/80], Loss: 1.5662\n",
            "Accuracy: 83.50%\n",
            "Epoch [19/80], Loss: 1.5839\n",
            "Accuracy: 81.80%\n",
            "Epoch [20/80], Loss: 1.5674\n",
            "Accuracy: 82.70%\n",
            "Epoch [21/80], Loss: 1.5140\n",
            "Accuracy: 84.40%\n",
            "Epoch [22/80], Loss: 1.5158\n",
            "Accuracy: 83.30%\n",
            "Epoch [23/80], Loss: 1.5571\n",
            "Accuracy: 83.20%\n",
            "Epoch [24/80], Loss: 1.6036\n",
            "Accuracy: 81.10%\n",
            "Epoch [25/80], Loss: 1.5062\n",
            "Accuracy: 82.70%\n",
            "Epoch [26/80], Loss: 1.4990\n",
            "Accuracy: 83.70%\n",
            "Epoch [27/80], Loss: 1.5641\n",
            "Accuracy: 83.00%\n",
            "Epoch [28/80], Loss: 1.5457\n",
            "Accuracy: 83.80%\n",
            "Epoch [29/80], Loss: 1.6353\n",
            "Accuracy: 81.50%\n",
            "Epoch [30/80], Loss: 1.5719\n",
            "Accuracy: 83.50%\n",
            "Epoch [31/80], Loss: 1.5119\n",
            "Accuracy: 83.60%\n",
            "Epoch [32/80], Loss: 1.5758\n",
            "Accuracy: 83.90%\n",
            "Epoch [33/80], Loss: 1.5955\n",
            "Accuracy: 82.40%\n",
            "Epoch [34/80], Loss: 1.5139\n",
            "Accuracy: 84.20%\n",
            "Epoch [35/80], Loss: 1.5394\n",
            "Accuracy: 84.10%\n",
            "Epoch [36/80], Loss: 1.5574\n",
            "Accuracy: 82.60%\n",
            "Epoch [37/80], Loss: 1.5832\n",
            "Accuracy: 83.00%\n",
            "Epoch [38/80], Loss: 1.5768\n",
            "Accuracy: 83.00%\n",
            "Epoch [39/80], Loss: 1.6036\n",
            "Accuracy: 81.20%\n",
            "Epoch [40/80], Loss: 1.5351\n",
            "Accuracy: 82.40%\n",
            "Epoch [41/80], Loss: 1.5758\n",
            "Accuracy: 81.80%\n",
            "Epoch [42/80], Loss: 1.5343\n",
            "Accuracy: 85.10%\n",
            "Epoch [43/80], Loss: 1.5342\n",
            "Accuracy: 84.00%\n",
            "Epoch [44/80], Loss: 1.5475\n",
            "Accuracy: 83.40%\n",
            "Epoch [45/80], Loss: 1.5354\n",
            "Accuracy: 82.90%\n",
            "Epoch [46/80], Loss: 1.5336\n",
            "Accuracy: 83.80%\n",
            "Epoch [47/80], Loss: 1.5249\n",
            "Accuracy: 83.10%\n",
            "Epoch [48/80], Loss: 1.5320\n",
            "Accuracy: 83.00%\n",
            "Epoch [49/80], Loss: 1.5506\n",
            "Accuracy: 82.40%\n",
            "Epoch [50/80], Loss: 1.5507\n",
            "Accuracy: 82.10%\n",
            "Epoch [51/80], Loss: 1.5341\n",
            "Accuracy: 84.20%\n",
            "Epoch [52/80], Loss: 1.5572\n",
            "Accuracy: 83.40%\n",
            "Epoch [53/80], Loss: 1.5477\n",
            "Accuracy: 82.90%\n",
            "Epoch [54/80], Loss: 1.5260\n",
            "Accuracy: 82.20%\n",
            "Epoch [55/80], Loss: 1.5244\n",
            "Accuracy: 83.60%\n",
            "Epoch [56/80], Loss: 1.5237\n",
            "Accuracy: 82.60%\n",
            "Epoch [57/80], Loss: 1.5553\n",
            "Accuracy: 82.70%\n",
            "Epoch [58/80], Loss: 1.5946\n",
            "Accuracy: 80.90%\n",
            "Epoch [59/80], Loss: 1.5470\n",
            "Accuracy: 84.00%\n",
            "Epoch [60/80], Loss: 1.5190\n",
            "Accuracy: 82.40%\n",
            "Epoch [61/80], Loss: 1.5394\n",
            "Accuracy: 80.70%\n",
            "Epoch [62/80], Loss: 1.5412\n",
            "Accuracy: 82.20%\n",
            "Epoch [63/80], Loss: 1.5469\n",
            "Accuracy: 82.80%\n",
            "Epoch [64/80], Loss: 1.5527\n",
            "Accuracy: 82.90%\n",
            "Epoch [65/80], Loss: 1.5216\n",
            "Accuracy: 83.10%\n",
            "Epoch [66/80], Loss: 1.5652\n",
            "Accuracy: 82.20%\n",
            "Epoch [67/80], Loss: 1.5161\n",
            "Accuracy: 83.80%\n",
            "Epoch [68/80], Loss: 1.5112\n",
            "Accuracy: 83.60%\n",
            "Epoch [69/80], Loss: 1.5240\n",
            "Accuracy: 83.20%\n",
            "Epoch [70/80], Loss: 1.5239\n",
            "Accuracy: 83.00%\n",
            "Epoch [71/80], Loss: 1.5247\n",
            "Accuracy: 81.90%\n",
            "Epoch [72/80], Loss: 1.5638\n",
            "Accuracy: 83.10%\n",
            "Epoch [73/80], Loss: 1.5649\n",
            "Accuracy: 83.60%\n",
            "Epoch [74/80], Loss: 1.5582\n",
            "Accuracy: 82.20%\n",
            "Epoch [75/80], Loss: 1.5293\n",
            "Accuracy: 83.60%\n",
            "Epoch [76/80], Loss: 1.5650\n",
            "Accuracy: 84.00%\n",
            "Epoch [77/80], Loss: 1.5444\n",
            "Accuracy: 84.50%\n",
            "Epoch [78/80], Loss: 1.4930\n",
            "Accuracy: 84.30%\n",
            "Epoch [79/80], Loss: 1.5238\n",
            "Accuracy: 84.30%\n",
            "Epoch [80/80], Loss: 1.5278\n",
            "Accuracy: 82.30%\n",
            "# of class (balanced train): Counter({0: 1200, 6: 1200, 7: 1200, 8: 1200, 9: 1200})\n",
            "# of class (balanced train): Counter({1: 1200, 2: 1200, 3: 1200, 4: 1200, 5: 1200})\n",
            "Epoch [1/80], Loss: 1.7088\n",
            "Accuracy: 77.80%\n",
            "Epoch [2/80], Loss: 1.7354\n",
            "Accuracy: 78.80%\n",
            "Epoch [3/80], Loss: 1.6161\n",
            "Accuracy: 79.40%\n",
            "Epoch [4/80], Loss: 1.6376\n",
            "Accuracy: 81.90%\n",
            "Epoch [5/80], Loss: 1.6948\n",
            "Accuracy: 80.60%\n",
            "Epoch [6/80], Loss: 1.5507\n",
            "Accuracy: 81.70%\n",
            "Epoch [7/80], Loss: 1.5991\n",
            "Accuracy: 81.20%\n",
            "Epoch [8/80], Loss: 1.5961\n",
            "Accuracy: 82.00%\n",
            "Epoch [9/80], Loss: 1.5601\n",
            "Accuracy: 81.70%\n",
            "Epoch [10/80], Loss: 1.5962\n",
            "Accuracy: 82.10%\n",
            "Epoch [11/80], Loss: 1.5550\n",
            "Accuracy: 82.40%\n",
            "Epoch [12/80], Loss: 1.5717\n",
            "Accuracy: 82.10%\n",
            "Epoch [13/80], Loss: 1.6448\n",
            "Accuracy: 81.50%\n",
            "Epoch [14/80], Loss: 1.5674\n",
            "Accuracy: 82.70%\n",
            "Epoch [15/80], Loss: 1.5906\n",
            "Accuracy: 83.10%\n",
            "Epoch [16/80], Loss: 1.6235\n",
            "Accuracy: 81.80%\n",
            "Epoch [17/80], Loss: 1.6179\n",
            "Accuracy: 84.20%\n",
            "Epoch [18/80], Loss: 1.5717\n",
            "Accuracy: 82.40%\n",
            "Epoch [19/80], Loss: 1.5776\n",
            "Accuracy: 83.40%\n",
            "Epoch [20/80], Loss: 1.5997\n",
            "Accuracy: 83.00%\n",
            "Epoch [21/80], Loss: 1.5808\n",
            "Accuracy: 81.00%\n",
            "Epoch [22/80], Loss: 1.5533\n",
            "Accuracy: 82.90%\n",
            "Epoch [23/80], Loss: 1.6156\n",
            "Accuracy: 82.60%\n",
            "Epoch [24/80], Loss: 1.5324\n",
            "Accuracy: 82.90%\n",
            "Epoch [25/80], Loss: 1.6092\n",
            "Accuracy: 81.70%\n",
            "Epoch [26/80], Loss: 1.5443\n",
            "Accuracy: 84.20%\n",
            "Epoch [27/80], Loss: 1.5681\n",
            "Accuracy: 82.70%\n",
            "Epoch [28/80], Loss: 1.5548\n",
            "Accuracy: 82.00%\n",
            "Epoch [29/80], Loss: 1.5245\n",
            "Accuracy: 83.10%\n",
            "Epoch [30/80], Loss: 1.5703\n",
            "Accuracy: 83.30%\n",
            "Epoch [31/80], Loss: 1.5937\n",
            "Accuracy: 83.80%\n",
            "Epoch [32/80], Loss: 1.6673\n",
            "Accuracy: 82.60%\n",
            "Epoch [33/80], Loss: 1.5298\n",
            "Accuracy: 83.60%\n",
            "Epoch [34/80], Loss: 1.5640\n",
            "Accuracy: 83.20%\n",
            "Epoch [35/80], Loss: 1.5342\n",
            "Accuracy: 84.10%\n",
            "Epoch [36/80], Loss: 1.5250\n",
            "Accuracy: 81.00%\n",
            "Epoch [37/80], Loss: 1.5657\n",
            "Accuracy: 83.20%\n",
            "Epoch [38/80], Loss: 1.5167\n",
            "Accuracy: 83.90%\n",
            "Epoch [39/80], Loss: 1.5545\n",
            "Accuracy: 83.90%\n",
            "Epoch [40/80], Loss: 1.5753\n",
            "Accuracy: 82.80%\n",
            "Epoch [41/80], Loss: 1.5433\n",
            "Accuracy: 83.00%\n",
            "Epoch [42/80], Loss: 1.5134\n",
            "Accuracy: 83.00%\n",
            "Epoch [43/80], Loss: 1.5133\n",
            "Accuracy: 84.80%\n",
            "Epoch [44/80], Loss: 1.5440\n",
            "Accuracy: 84.00%\n",
            "Epoch [45/80], Loss: 1.5790\n",
            "Accuracy: 82.10%\n",
            "Epoch [46/80], Loss: 1.5681\n",
            "Accuracy: 82.70%\n",
            "Epoch [47/80], Loss: 1.5368\n",
            "Accuracy: 82.40%\n",
            "Epoch [48/80], Loss: 1.5544\n",
            "Accuracy: 79.60%\n",
            "Epoch [49/80], Loss: 1.5949\n",
            "Accuracy: 83.80%\n",
            "Epoch [50/80], Loss: 1.5741\n",
            "Accuracy: 82.30%\n",
            "Epoch [51/80], Loss: 1.5818\n",
            "Accuracy: 82.30%\n",
            "Epoch [52/80], Loss: 1.5551\n",
            "Accuracy: 84.60%\n",
            "Epoch [53/80], Loss: 1.5343\n",
            "Accuracy: 83.30%\n",
            "Epoch [54/80], Loss: 1.5163\n",
            "Accuracy: 83.00%\n",
            "Epoch [55/80], Loss: 1.5654\n",
            "Accuracy: 83.70%\n",
            "Epoch [56/80], Loss: 1.5271\n",
            "Accuracy: 84.30%\n",
            "Epoch [57/80], Loss: 1.5573\n",
            "Accuracy: 83.80%\n",
            "Epoch [58/80], Loss: 1.5237\n",
            "Accuracy: 82.10%\n",
            "Epoch [59/80], Loss: 1.5451\n",
            "Accuracy: 81.70%\n",
            "Epoch [60/80], Loss: 1.5597\n",
            "Accuracy: 83.60%\n",
            "Epoch [61/80], Loss: 1.5545\n",
            "Accuracy: 82.80%\n",
            "Epoch [62/80], Loss: 1.5674\n",
            "Accuracy: 84.20%\n",
            "Epoch [63/80], Loss: 1.5180\n",
            "Accuracy: 84.20%\n",
            "Epoch [64/80], Loss: 1.6191\n",
            "Accuracy: 83.10%\n",
            "Epoch [65/80], Loss: 1.5055\n",
            "Accuracy: 84.00%\n",
            "Epoch [66/80], Loss: 1.5445\n",
            "Accuracy: 83.90%\n",
            "Epoch [67/80], Loss: 1.5553\n",
            "Accuracy: 84.10%\n",
            "Epoch [68/80], Loss: 1.5444\n",
            "Accuracy: 83.70%\n",
            "Epoch [69/80], Loss: 1.5709\n",
            "Accuracy: 83.80%\n",
            "Epoch [70/80], Loss: 1.5449\n",
            "Accuracy: 83.50%\n",
            "Epoch [71/80], Loss: 1.5965\n",
            "Accuracy: 84.10%\n",
            "Epoch [72/80], Loss: 1.5251\n",
            "Accuracy: 83.40%\n",
            "Epoch [73/80], Loss: 1.5136\n",
            "Accuracy: 83.70%\n",
            "Epoch [74/80], Loss: 1.5131\n",
            "Accuracy: 84.00%\n",
            "Epoch [75/80], Loss: 1.5551\n",
            "Accuracy: 84.50%\n",
            "Epoch [76/80], Loss: 1.5446\n",
            "Accuracy: 84.10%\n",
            "Epoch [77/80], Loss: 1.5119\n",
            "Accuracy: 84.50%\n",
            "Epoch [78/80], Loss: 1.5320\n",
            "Accuracy: 84.00%\n",
            "Epoch [79/80], Loss: 1.5332\n",
            "Accuracy: 83.90%\n",
            "Epoch [80/80], Loss: 1.5205\n",
            "Accuracy: 83.50%\n",
            "# of class (balanced train): Counter({0: 1200, 6: 1200, 7: 1200, 8: 1200, 9: 1200})\n",
            "# of class (balanced train): Counter({1: 1200, 2: 1200, 3: 1200, 4: 1200, 5: 1200})\n",
            "Epoch [1/80], Loss: 1.7711\n",
            "Accuracy: 77.30%\n",
            "Epoch [2/80], Loss: 1.6643\n",
            "Accuracy: 78.40%\n",
            "Epoch [3/80], Loss: 1.6946\n",
            "Accuracy: 78.10%\n",
            "Epoch [4/80], Loss: 1.6818\n",
            "Accuracy: 79.00%\n",
            "Epoch [5/80], Loss: 1.6466\n",
            "Accuracy: 79.50%\n",
            "Epoch [6/80], Loss: 1.6209\n",
            "Accuracy: 82.70%\n",
            "Epoch [7/80], Loss: 1.5548\n",
            "Accuracy: 79.10%\n",
            "Epoch [8/80], Loss: 1.6372\n",
            "Accuracy: 82.10%\n",
            "Epoch [9/80], Loss: 1.5490\n",
            "Accuracy: 81.70%\n",
            "Epoch [10/80], Loss: 1.5533\n",
            "Accuracy: 82.90%\n",
            "Epoch [11/80], Loss: 1.5887\n",
            "Accuracy: 78.80%\n",
            "Epoch [12/80], Loss: 1.5805\n",
            "Accuracy: 79.10%\n",
            "Epoch [13/80], Loss: 1.6553\n",
            "Accuracy: 82.30%\n",
            "Epoch [14/80], Loss: 1.6025\n",
            "Accuracy: 82.70%\n",
            "Epoch [15/80], Loss: 1.5623\n",
            "Accuracy: 80.80%\n",
            "Epoch [16/80], Loss: 1.5929\n",
            "Accuracy: 81.30%\n",
            "Epoch [17/80], Loss: 1.5928\n",
            "Accuracy: 82.90%\n",
            "Epoch [18/80], Loss: 1.5376\n",
            "Accuracy: 83.60%\n",
            "Epoch [19/80], Loss: 1.5352\n",
            "Accuracy: 83.30%\n",
            "Epoch [20/80], Loss: 1.5351\n",
            "Accuracy: 84.20%\n",
            "Epoch [21/80], Loss: 1.5798\n",
            "Accuracy: 82.60%\n",
            "Epoch [22/80], Loss: 1.5490\n",
            "Accuracy: 83.90%\n",
            "Epoch [23/80], Loss: 1.5334\n",
            "Accuracy: 83.20%\n",
            "Epoch [24/80], Loss: 1.5332\n",
            "Accuracy: 82.40%\n",
            "Epoch [25/80], Loss: 1.5655\n",
            "Accuracy: 83.90%\n",
            "Epoch [26/80], Loss: 1.5156\n",
            "Accuracy: 83.60%\n",
            "Epoch [27/80], Loss: 1.6028\n",
            "Accuracy: 82.50%\n",
            "Epoch [28/80], Loss: 1.5830\n",
            "Accuracy: 83.60%\n",
            "Epoch [29/80], Loss: 1.5828\n",
            "Accuracy: 83.90%\n",
            "Epoch [30/80], Loss: 1.5260\n",
            "Accuracy: 84.80%\n",
            "Epoch [31/80], Loss: 1.5637\n",
            "Accuracy: 82.30%\n",
            "Epoch [32/80], Loss: 1.5335\n",
            "Accuracy: 83.20%\n",
            "Epoch [33/80], Loss: 1.5358\n",
            "Accuracy: 83.50%\n",
            "Epoch [34/80], Loss: 1.5438\n",
            "Accuracy: 84.60%\n",
            "Epoch [35/80], Loss: 1.5901\n",
            "Accuracy: 83.80%\n",
            "Epoch [36/80], Loss: 1.5357\n",
            "Accuracy: 83.60%\n",
            "Epoch [37/80], Loss: 1.5866\n",
            "Accuracy: 84.00%\n",
            "Epoch [38/80], Loss: 1.5467\n",
            "Accuracy: 84.10%\n",
            "Epoch [39/80], Loss: 1.5695\n",
            "Accuracy: 83.90%\n",
            "Epoch [40/80], Loss: 1.5032\n",
            "Accuracy: 83.80%\n",
            "Epoch [41/80], Loss: 1.5341\n",
            "Accuracy: 84.30%\n",
            "Epoch [42/80], Loss: 1.5465\n",
            "Accuracy: 84.10%\n",
            "Epoch [43/80], Loss: 1.5745\n",
            "Accuracy: 84.30%\n",
            "Epoch [44/80], Loss: 1.5248\n",
            "Accuracy: 84.30%\n",
            "Epoch [45/80], Loss: 1.5158\n",
            "Accuracy: 83.40%\n",
            "Epoch [46/80], Loss: 1.5778\n",
            "Accuracy: 82.30%\n",
            "Epoch [47/80], Loss: 1.5433\n",
            "Accuracy: 83.20%\n",
            "Epoch [48/80], Loss: 1.5981\n",
            "Accuracy: 83.40%\n",
            "Epoch [49/80], Loss: 1.5203\n",
            "Accuracy: 83.90%\n",
            "Epoch [50/80], Loss: 1.6100\n",
            "Accuracy: 83.60%\n",
            "Epoch [51/80], Loss: 1.4942\n",
            "Accuracy: 83.00%\n",
            "Epoch [52/80], Loss: 1.5315\n",
            "Accuracy: 84.40%\n",
            "Epoch [53/80], Loss: 1.5301\n",
            "Accuracy: 82.80%\n",
            "Epoch [54/80], Loss: 1.5254\n",
            "Accuracy: 83.40%\n",
            "Epoch [55/80], Loss: 1.5688\n",
            "Accuracy: 83.40%\n",
            "Epoch [56/80], Loss: 1.5450\n",
            "Accuracy: 84.10%\n",
            "Epoch [57/80], Loss: 1.5630\n",
            "Accuracy: 84.30%\n",
            "Epoch [58/80], Loss: 1.5342\n",
            "Accuracy: 83.10%\n",
            "Epoch [59/80], Loss: 1.6126\n",
            "Accuracy: 83.80%\n",
            "Epoch [60/80], Loss: 1.5067\n",
            "Accuracy: 84.10%\n",
            "Epoch [61/80], Loss: 1.5369\n",
            "Accuracy: 83.40%\n",
            "Epoch [62/80], Loss: 1.5028\n",
            "Accuracy: 83.70%\n",
            "Epoch [63/80], Loss: 1.4820\n",
            "Accuracy: 83.40%\n",
            "Epoch [64/80], Loss: 1.5239\n",
            "Accuracy: 82.90%\n",
            "Epoch [65/80], Loss: 1.4985\n",
            "Accuracy: 83.20%\n",
            "Epoch [66/80], Loss: 1.5248\n",
            "Accuracy: 83.40%\n",
            "Epoch [67/80], Loss: 1.5377\n",
            "Accuracy: 84.20%\n",
            "Epoch [68/80], Loss: 1.5315\n",
            "Accuracy: 83.40%\n",
            "Epoch [69/80], Loss: 1.4987\n",
            "Accuracy: 83.70%\n",
            "Epoch [70/80], Loss: 1.5464\n",
            "Accuracy: 83.30%\n",
            "Epoch [71/80], Loss: 1.4924\n",
            "Accuracy: 83.20%\n",
            "Epoch [72/80], Loss: 1.5466\n",
            "Accuracy: 83.30%\n",
            "Epoch [73/80], Loss: 1.5048\n",
            "Accuracy: 84.10%\n",
            "Epoch [74/80], Loss: 1.5424\n",
            "Accuracy: 84.30%\n",
            "Epoch [75/80], Loss: 1.5971\n",
            "Accuracy: 84.60%\n",
            "Epoch [76/80], Loss: 1.5368\n",
            "Accuracy: 83.70%\n",
            "Epoch [77/80], Loss: 1.4776\n",
            "Accuracy: 84.60%\n",
            "Epoch [78/80], Loss: 1.5683\n",
            "Accuracy: 82.80%\n",
            "Epoch [79/80], Loss: 1.4945\n",
            "Accuracy: 83.10%\n",
            "Epoch [80/80], Loss: 1.5474\n",
            "Accuracy: 82.90%\n",
            "# of class (balanced train): Counter({0: 1200, 6: 1200, 7: 1200, 8: 1200, 9: 1200})\n",
            "# of class (balanced train): Counter({1: 1200, 2: 1200, 3: 1200, 4: 1200, 5: 1200})\n",
            "Epoch [1/80], Loss: 1.6983\n",
            "Accuracy: 74.60%\n",
            "Epoch [2/80], Loss: 1.6788\n",
            "Accuracy: 75.30%\n",
            "Epoch [3/80], Loss: 1.6324\n",
            "Accuracy: 76.30%\n",
            "Epoch [4/80], Loss: 1.7297\n",
            "Accuracy: 75.60%\n",
            "Epoch [5/80], Loss: 1.6966\n",
            "Accuracy: 77.80%\n",
            "Epoch [6/80], Loss: 1.6623\n",
            "Accuracy: 82.10%\n",
            "Epoch [7/80], Loss: 1.5850\n",
            "Accuracy: 81.30%\n",
            "Epoch [8/80], Loss: 1.5974\n",
            "Accuracy: 81.20%\n",
            "Epoch [9/80], Loss: 1.5958\n",
            "Accuracy: 80.80%\n",
            "Epoch [10/80], Loss: 1.5515\n",
            "Accuracy: 80.60%\n",
            "Epoch [11/80], Loss: 1.6054\n",
            "Accuracy: 79.20%\n",
            "Epoch [12/80], Loss: 1.5884\n",
            "Accuracy: 79.30%\n",
            "Epoch [13/80], Loss: 1.6364\n",
            "Accuracy: 81.00%\n",
            "Epoch [14/80], Loss: 1.6294\n",
            "Accuracy: 82.40%\n",
            "Epoch [15/80], Loss: 1.5553\n",
            "Accuracy: 83.90%\n",
            "Epoch [16/80], Loss: 1.6100\n",
            "Accuracy: 82.20%\n",
            "Epoch [17/80], Loss: 1.5832\n",
            "Accuracy: 83.60%\n",
            "Epoch [18/80], Loss: 1.5939\n",
            "Accuracy: 81.40%\n",
            "Epoch [19/80], Loss: 1.5952\n",
            "Accuracy: 81.90%\n",
            "Epoch [20/80], Loss: 1.5155\n",
            "Accuracy: 84.60%\n",
            "Epoch [21/80], Loss: 1.6327\n",
            "Accuracy: 84.10%\n",
            "Epoch [22/80], Loss: 1.5989\n",
            "Accuracy: 83.40%\n",
            "Epoch [23/80], Loss: 1.5861\n",
            "Accuracy: 83.20%\n",
            "Epoch [24/80], Loss: 1.6052\n",
            "Accuracy: 82.70%\n",
            "Epoch [25/80], Loss: 1.5628\n",
            "Accuracy: 83.60%\n",
            "Epoch [26/80], Loss: 1.5697\n",
            "Accuracy: 84.00%\n",
            "Epoch [27/80], Loss: 1.5866\n",
            "Accuracy: 83.40%\n",
            "Epoch [28/80], Loss: 1.5694\n",
            "Accuracy: 84.20%\n",
            "Epoch [29/80], Loss: 1.5531\n",
            "Accuracy: 84.30%\n",
            "Epoch [30/80], Loss: 1.5308\n",
            "Accuracy: 84.40%\n",
            "Epoch [31/80], Loss: 1.5282\n",
            "Accuracy: 83.60%\n",
            "Epoch [32/80], Loss: 1.5764\n",
            "Accuracy: 83.50%\n",
            "Epoch [33/80], Loss: 1.5349\n",
            "Accuracy: 85.00%\n",
            "Epoch [34/80], Loss: 1.6353\n",
            "Accuracy: 83.80%\n",
            "Epoch [35/80], Loss: 1.5383\n",
            "Accuracy: 82.20%\n",
            "Epoch [36/80], Loss: 1.5368\n",
            "Accuracy: 83.10%\n",
            "Epoch [37/80], Loss: 1.5346\n",
            "Accuracy: 83.60%\n",
            "Epoch [38/80], Loss: 1.5248\n",
            "Accuracy: 84.30%\n",
            "Epoch [39/80], Loss: 1.5464\n",
            "Accuracy: 82.80%\n",
            "Epoch [40/80], Loss: 1.5447\n",
            "Accuracy: 83.60%\n",
            "Epoch [41/80], Loss: 1.5820\n",
            "Accuracy: 84.50%\n",
            "Epoch [42/80], Loss: 1.5073\n",
            "Accuracy: 83.50%\n",
            "Epoch [43/80], Loss: 1.5445\n",
            "Accuracy: 84.60%\n",
            "Epoch [44/80], Loss: 1.5692\n",
            "Accuracy: 84.70%\n",
            "Epoch [45/80], Loss: 1.5345\n",
            "Accuracy: 84.60%\n",
            "Epoch [46/80], Loss: 1.6061\n",
            "Accuracy: 83.70%\n",
            "Epoch [47/80], Loss: 1.5747\n",
            "Accuracy: 82.30%\n",
            "Epoch [48/80], Loss: 1.5156\n",
            "Accuracy: 83.90%\n",
            "Epoch [49/80], Loss: 1.5964\n",
            "Accuracy: 83.10%\n",
            "Epoch [50/80], Loss: 1.5444\n",
            "Accuracy: 83.70%\n",
            "Epoch [51/80], Loss: 1.5409\n",
            "Accuracy: 84.10%\n",
            "Epoch [52/80], Loss: 1.5257\n",
            "Accuracy: 84.50%\n",
            "Epoch [53/80], Loss: 1.5370\n",
            "Accuracy: 83.80%\n",
            "Epoch [54/80], Loss: 1.5626\n",
            "Accuracy: 81.90%\n",
            "Epoch [55/80], Loss: 1.5718\n",
            "Accuracy: 82.60%\n",
            "Epoch [56/80], Loss: 1.5215\n",
            "Accuracy: 82.80%\n",
            "Epoch [57/80], Loss: 1.5964\n",
            "Accuracy: 83.50%\n",
            "Epoch [58/80], Loss: 1.5660\n",
            "Accuracy: 82.10%\n",
            "Epoch [59/80], Loss: 1.5337\n",
            "Accuracy: 84.70%\n",
            "Epoch [60/80], Loss: 1.5237\n",
            "Accuracy: 84.50%\n",
            "Epoch [61/80], Loss: 1.5263\n",
            "Accuracy: 84.20%\n",
            "Epoch [62/80], Loss: 1.5751\n",
            "Accuracy: 83.90%\n",
            "Epoch [63/80], Loss: 1.5245\n",
            "Accuracy: 84.10%\n",
            "Epoch [64/80], Loss: 1.5403\n",
            "Accuracy: 82.60%\n",
            "Epoch [65/80], Loss: 1.5345\n",
            "Accuracy: 83.40%\n",
            "Epoch [66/80], Loss: 1.5081\n",
            "Accuracy: 82.90%\n",
            "Epoch [67/80], Loss: 1.5646\n",
            "Accuracy: 84.30%\n",
            "Epoch [68/80], Loss: 1.5338\n",
            "Accuracy: 84.70%\n",
            "Epoch [69/80], Loss: 1.5235\n",
            "Accuracy: 83.70%\n",
            "Epoch [70/80], Loss: 1.5139\n",
            "Accuracy: 84.40%\n",
            "Epoch [71/80], Loss: 1.6258\n",
            "Accuracy: 84.00%\n",
            "Epoch [72/80], Loss: 1.5549\n",
            "Accuracy: 84.30%\n",
            "Epoch [73/80], Loss: 1.5512\n",
            "Accuracy: 83.70%\n",
            "Epoch [74/80], Loss: 1.5078\n",
            "Accuracy: 84.80%\n",
            "Epoch [75/80], Loss: 1.5253\n",
            "Accuracy: 85.20%\n",
            "Epoch [76/80], Loss: 1.5438\n",
            "Accuracy: 82.60%\n",
            "Epoch [77/80], Loss: 1.5436\n",
            "Accuracy: 84.60%\n",
            "Epoch [78/80], Loss: 1.5627\n",
            "Accuracy: 85.50%\n",
            "Epoch [79/80], Loss: 1.5909\n",
            "Accuracy: 84.40%\n",
            "Epoch [80/80], Loss: 1.5641\n",
            "Accuracy: 84.90%\n",
            "# of class (balanced train): Counter({0: 1200, 6: 1200, 7: 1200, 8: 1200, 9: 1200})\n",
            "# of class (balanced train): Counter({1: 1200, 2: 1200, 3: 1200, 4: 1200, 5: 1200})\n",
            "Epoch [1/80], Loss: 1.7087\n",
            "Accuracy: 76.40%\n",
            "Epoch [2/80], Loss: 1.7274\n",
            "Accuracy: 77.80%\n",
            "Epoch [3/80], Loss: 1.6374\n",
            "Accuracy: 81.00%\n",
            "Epoch [4/80], Loss: 1.6272\n",
            "Accuracy: 80.50%\n",
            "Epoch [5/80], Loss: 1.6279\n",
            "Accuracy: 81.90%\n",
            "Epoch [6/80], Loss: 1.5838\n",
            "Accuracy: 82.40%\n",
            "Epoch [7/80], Loss: 1.5861\n",
            "Accuracy: 80.20%\n",
            "Epoch [8/80], Loss: 1.5592\n",
            "Accuracy: 82.40%\n",
            "Epoch [9/80], Loss: 1.5786\n",
            "Accuracy: 80.20%\n",
            "Epoch [10/80], Loss: 1.5235\n",
            "Accuracy: 83.10%\n",
            "Epoch [11/80], Loss: 1.6272\n",
            "Accuracy: 81.30%\n",
            "Epoch [12/80], Loss: 1.5103\n",
            "Accuracy: 80.10%\n",
            "Epoch [13/80], Loss: 1.6161\n",
            "Accuracy: 83.60%\n",
            "Epoch [14/80], Loss: 1.5193\n",
            "Accuracy: 82.60%\n",
            "Epoch [15/80], Loss: 1.5485\n",
            "Accuracy: 82.70%\n",
            "Epoch [16/80], Loss: 1.5886\n",
            "Accuracy: 81.90%\n",
            "Epoch [17/80], Loss: 1.5633\n",
            "Accuracy: 83.90%\n",
            "Epoch [18/80], Loss: 1.5592\n",
            "Accuracy: 82.70%\n",
            "Epoch [19/80], Loss: 1.5877\n",
            "Accuracy: 84.00%\n",
            "Epoch [20/80], Loss: 1.5850\n",
            "Accuracy: 83.80%\n",
            "Epoch [21/80], Loss: 1.5714\n",
            "Accuracy: 83.00%\n",
            "Epoch [22/80], Loss: 1.6045\n",
            "Accuracy: 78.00%\n",
            "Epoch [23/80], Loss: 1.5898\n",
            "Accuracy: 83.50%\n",
            "Epoch [24/80], Loss: 1.5761\n",
            "Accuracy: 83.30%\n",
            "Epoch [25/80], Loss: 1.5920\n",
            "Accuracy: 83.00%\n",
            "Epoch [26/80], Loss: 1.5352\n",
            "Accuracy: 82.70%\n",
            "Epoch [27/80], Loss: 1.5769\n",
            "Accuracy: 83.90%\n",
            "Epoch [28/80], Loss: 1.5032\n",
            "Accuracy: 83.70%\n",
            "Epoch [29/80], Loss: 1.6123\n",
            "Accuracy: 84.00%\n",
            "Epoch [30/80], Loss: 1.5762\n",
            "Accuracy: 83.70%\n",
            "Epoch [31/80], Loss: 1.5410\n",
            "Accuracy: 83.50%\n",
            "Epoch [32/80], Loss: 1.5496\n",
            "Accuracy: 85.00%\n",
            "Epoch [33/80], Loss: 1.6375\n",
            "Accuracy: 83.70%\n",
            "Epoch [34/80], Loss: 1.5039\n",
            "Accuracy: 83.70%\n",
            "Epoch [35/80], Loss: 1.5718\n",
            "Accuracy: 84.50%\n",
            "Epoch [36/80], Loss: 1.5705\n",
            "Accuracy: 81.80%\n",
            "Epoch [37/80], Loss: 1.5124\n",
            "Accuracy: 84.10%\n",
            "Epoch [38/80], Loss: 1.4765\n",
            "Accuracy: 83.90%\n",
            "Epoch [39/80], Loss: 1.5527\n",
            "Accuracy: 83.10%\n",
            "Epoch [40/80], Loss: 1.5438\n",
            "Accuracy: 82.90%\n",
            "Epoch [41/80], Loss: 1.5047\n",
            "Accuracy: 84.80%\n",
            "Epoch [42/80], Loss: 1.5663\n",
            "Accuracy: 84.20%\n",
            "Epoch [43/80], Loss: 1.5530\n",
            "Accuracy: 84.70%\n",
            "Epoch [44/80], Loss: 1.5065\n",
            "Accuracy: 83.10%\n",
            "Epoch [45/80], Loss: 1.5151\n",
            "Accuracy: 84.80%\n",
            "Epoch [46/80], Loss: 1.5243\n",
            "Accuracy: 84.10%\n",
            "Epoch [47/80], Loss: 1.5338\n",
            "Accuracy: 84.30%\n",
            "Epoch [48/80], Loss: 1.5608\n",
            "Accuracy: 84.20%\n",
            "Epoch [49/80], Loss: 1.5385\n",
            "Accuracy: 84.90%\n",
            "Epoch [50/80], Loss: 1.5211\n",
            "Accuracy: 82.10%\n",
            "Epoch [51/80], Loss: 1.4928\n",
            "Accuracy: 85.30%\n",
            "Epoch [52/80], Loss: 1.5234\n",
            "Accuracy: 83.90%\n",
            "Epoch [53/80], Loss: 1.5340\n",
            "Accuracy: 85.20%\n",
            "Epoch [54/80], Loss: 1.5451\n",
            "Accuracy: 84.50%\n",
            "Epoch [55/80], Loss: 1.5348\n",
            "Accuracy: 83.80%\n",
            "Epoch [56/80], Loss: 1.5146\n",
            "Accuracy: 85.60%\n",
            "Epoch [57/80], Loss: 1.5273\n",
            "Accuracy: 84.70%\n",
            "Epoch [58/80], Loss: 1.5249\n",
            "Accuracy: 84.70%\n",
            "Epoch [59/80], Loss: 1.5652\n",
            "Accuracy: 83.50%\n",
            "Epoch [60/80], Loss: 1.5553\n",
            "Accuracy: 84.90%\n",
            "Epoch [61/80], Loss: 1.5138\n",
            "Accuracy: 84.60%\n",
            "Epoch [62/80], Loss: 1.5497\n",
            "Accuracy: 81.60%\n",
            "Epoch [63/80], Loss: 1.4945\n",
            "Accuracy: 83.60%\n",
            "Epoch [64/80], Loss: 1.5397\n",
            "Accuracy: 83.90%\n",
            "Epoch [65/80], Loss: 1.5071\n",
            "Accuracy: 82.40%\n",
            "Epoch [66/80], Loss: 1.5227\n",
            "Accuracy: 84.00%\n",
            "Epoch [67/80], Loss: 1.5148\n",
            "Accuracy: 83.70%\n",
            "Epoch [68/80], Loss: 1.5428\n",
            "Accuracy: 83.30%\n",
            "Epoch [69/80], Loss: 1.5464\n",
            "Accuracy: 84.10%\n",
            "Epoch [70/80], Loss: 1.5274\n",
            "Accuracy: 82.50%\n",
            "Epoch [71/80], Loss: 1.5164\n",
            "Accuracy: 84.00%\n",
            "Epoch [72/80], Loss: 1.5135\n",
            "Accuracy: 84.00%\n",
            "Epoch [73/80], Loss: 1.5172\n",
            "Accuracy: 85.20%\n",
            "Epoch [74/80], Loss: 1.5109\n",
            "Accuracy: 84.60%\n",
            "Epoch [75/80], Loss: 1.5448\n",
            "Accuracy: 84.80%\n",
            "Epoch [76/80], Loss: 1.5070\n",
            "Accuracy: 83.30%\n",
            "Epoch [77/80], Loss: 1.5368\n",
            "Accuracy: 83.30%\n",
            "Epoch [78/80], Loss: 1.4967\n",
            "Accuracy: 82.30%\n",
            "Epoch [79/80], Loss: 1.5363\n",
            "Accuracy: 83.70%\n",
            "Epoch [80/80], Loss: 1.5254\n",
            "Accuracy: 84.20%\n"
          ]
        }
      ],
      "source": [
        "proba_list = []\n",
        "\n",
        "num_epochs = 80\n",
        "for i in range(5):\n",
        "    # Count the occurrences of each class in the training set\n",
        "    train_counter = Counter(train_y)\n",
        "    valid_counter = Counter(valid_y)\n",
        "    # Calculate the target count for each class (1200)\n",
        "    target_count = 1200\n",
        "\n",
        "    # Create empty lists to store the balanced data\n",
        "    balanced_train_X1 = []\n",
        "    balanced_train_y1 = []\n",
        "\n",
        "    # Specify the classes to balance\n",
        "    classes_to_balance1 = [0, 9, 8, 7, 6]\n",
        "\n",
        "    # Iterate over the classes\n",
        "    for class_label in train_counter.keys():\n",
        "        # Check if the current class is one of the classes to balance\n",
        "        if class_label in classes_to_balance1:\n",
        "            # Get the samples and labels for the current class\n",
        "            class_indices = np.where(train_y == class_label)[0]\n",
        "            class_samples = train_X[class_indices]\n",
        "            class_labels = train_y[class_indices]\n",
        "\n",
        "            # Shuffle the samples and labels\n",
        "            shuffled_indices = np.random.permutation(len(class_indices))\n",
        "            shuffled_samples = class_samples[shuffled_indices]\n",
        "            shuffled_labels = class_labels[shuffled_indices]\n",
        "\n",
        "            # Select the first target_count samples for the current class\n",
        "            selected_samples = shuffled_samples[:target_count]\n",
        "            selected_labels = shuffled_labels[:target_count]\n",
        "\n",
        "            # Add the selected samples and labels to the balanced data\n",
        "            balanced_train_X1.extend(selected_samples)\n",
        "            balanced_train_y1.extend(selected_labels)\n",
        "\n",
        "    # Convert the balanced data lists to numpy arrays\n",
        "    balanced_train_X1 = np.array(balanced_train_X1)\n",
        "    balanced_train_y1 = np.array(balanced_train_y1)\n",
        "\n",
        "    # Check the class distribution of the balanced training data\n",
        "    print('# of class (balanced train):', Counter(balanced_train_y1))\n",
        "\n",
        "    # Create empty lists to store the balanced data\n",
        "    balanced_train_X2 = []\n",
        "    balanced_train_y2 = []\n",
        "\n",
        "    # Specify the classes to balance\n",
        "    classes_to_balance2 = [1,2,3,4,5]\n",
        "\n",
        "    # Iterate over the classes\n",
        "    for class_label in train_counter.keys():\n",
        "        # Check if the current class is one of the classes to balance\n",
        "        if class_label in classes_to_balance2:\n",
        "            # Get the samples and labels for the current class\n",
        "            class_indices = np.where(train_y == class_label)[0]\n",
        "            class_samples = train_X[class_indices]\n",
        "            class_labels = train_y[class_indices]\n",
        "\n",
        "            # Shuffle the samples and labels\n",
        "            shuffled_indices = np.random.permutation(len(class_indices))\n",
        "            shuffled_samples = class_samples[shuffled_indices]\n",
        "            shuffled_labels = class_labels[shuffled_indices]\n",
        "\n",
        "            # If there are fewer samples than the target, duplicate them\n",
        "            if len(shuffled_samples) < target_count:\n",
        "                factor = target_count // len(shuffled_samples)\n",
        "                remainder = target_count % len(shuffled_samples)\n",
        "                shuffled_samples = np.concatenate([shuffled_samples]*factor + [shuffled_samples[:remainder]])\n",
        "                shuffled_labels = np.concatenate([shuffled_labels]*factor + [shuffled_labels[:remainder]])\n",
        "        \n",
        "            # Select the first target_count samples for the current class\n",
        "            selected_samples = shuffled_samples[:target_count]\n",
        "            selected_labels = shuffled_labels[:target_count]\n",
        "\n",
        "            # Add the selected samples and labels to the balanced data\n",
        "            balanced_train_X2.extend(selected_samples)\n",
        "            balanced_train_y2.extend(selected_labels)\n",
        "\n",
        "    # Convert the balanced data lists to numpy arrays\n",
        "    balanced_train_X2 = np.array(balanced_train_X2)\n",
        "    balanced_train_y2 = np.array(balanced_train_y2)\n",
        "\n",
        "    # Check the class distribution of the balanced training data\n",
        "    print('# of class (balanced train):', Counter(balanced_train_y2))\n",
        "\n",
        "    # 합치기 전에 형식이 맞는지 확인하세요. (예: balanced_train_X1.shape == balanced_train_X2.shape)\n",
        "    assert balanced_train_X1.shape[1:] == balanced_train_X2.shape[1:], \"Train X shapes do not match\"\n",
        "    assert balanced_train_y1.shape[1:] == balanced_train_y2.shape[1:], \"Train y shapes do not match\"\n",
        "\n",
        "    # X 배열 합치기\n",
        "    balanced_train_X = np.concatenate((balanced_train_X1, balanced_train_X2), axis=0)\n",
        "\n",
        "    # y 배열 합치기\n",
        "    balanced_train_y = np.concatenate((balanced_train_y1, balanced_train_y2), axis=0)\n",
        "\n",
        "    train_images, train_labels = balanced_train_X, balanced_train_y\n",
        "\n",
        "    valid_images, valid_labels = valid_X, valid_y\n",
        "\n",
        "    # Preprocess the dataset (normalize and convert to tensors)\n",
        "    test_images = test_X\n",
        "    train_images, valid_images = train_images / 255.0, valid_images / 255.0\n",
        "    test_images = test_images / 255.0\n",
        "\n",
        "    train_images = torch.tensor(train_images, dtype=torch.float32).reshape(-1, 28*28)\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "    valid_images = torch.tensor(valid_images, dtype=torch.float32).reshape(-1, 28*28)\n",
        "    valid_labels = torch.tensor(valid_labels, dtype=torch.long)\n",
        "    test_images = torch.Tensor(test_images).reshape(-1, 28*28)\n",
        "\n",
        "    # Create DataLoader for training and testing sets\n",
        "    train_dataset = TensorDataset(train_images, train_labels)\n",
        "    valid_dataset = TensorDataset(valid_images, valid_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # Create the model\n",
        "    input_size = 28*28\n",
        "    num_classes = 10\n",
        "    model = MLP_classifier(input_size, num_classes)\n",
        "\n",
        "    # Set up the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model using the train method\n",
        "    model.train(train_loader, valid_loader, criterion, optimizer, num_epochs)\n",
        "    proba_list.append(model.predict_proba(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W1TbqBSWSQHi"
      },
      "outputs": [],
      "source": [
        "results = torch.zeros_like(proba_list[0])\n",
        "for proba in proba_list:\n",
        "    results += proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pW2vBBh9SQHi"
      },
      "outputs": [],
      "source": [
        "predicted = results.argmax(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ztADGWjASQHj"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame({\"index\":np.arange(len(predicted)), \"label\": predicted})\n",
        "result.to_csv(\"result_ensemble.csv\", index=None)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "minch",
      "language": "python",
      "name": "minch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}